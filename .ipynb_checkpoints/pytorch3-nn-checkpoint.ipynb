{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "train = datasets.MNIST(\"\", train = True, download = True,\n",
    "                      transform = transforms.Compose([transforms.ToTensor()]))\n",
    "test =  datasets.MNIST(\"\", train = False, download = True,\n",
    "                      transform = transforms.Compose([transforms.ToTensor()]))\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size= 10, shuffle = True)\n",
    "testset = torch.utils.data.DataLoader(train, batch_size= 10, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784,64)# fc is fully connected\n",
    "        self.fc2 = nn.Linear(64,64)\n",
    "        self.fc3 = nn.Linear(64,64)\n",
    "        self.fc4 = nn.Linear(64,10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x)) \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim = 1)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "        \n",
    "net = Net()\n",
    "print(net)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5730, 0.5925, 0.7351, 0.3205, 0.1186, 0.1529, 0.9412, 0.6921, 0.0336,\n",
       "         0.8244, 0.1237, 0.8518, 0.3948, 0.7652, 0.9549, 0.6930, 0.0212, 0.8658,\n",
       "         0.7576, 0.5824, 0.2592, 0.0623, 0.5802, 0.1044, 0.5917, 0.2128, 0.9771,\n",
       "         0.7994, 0.9880, 0.3988, 0.2010, 0.2300, 0.0235, 0.0330, 0.7596, 0.1475,\n",
       "         0.3574, 0.5761, 0.3106, 0.9951, 0.3773, 0.2957, 0.0880, 0.2735, 0.0521,\n",
       "         0.7190, 0.0245, 0.4835, 0.4020, 0.8678, 0.4082, 0.3048, 0.7310, 0.7642,\n",
       "         0.4665, 0.9260, 0.9316, 0.3932, 0.7897, 0.0391, 0.4797, 0.3019, 0.9695,\n",
       "         0.6737, 0.7238, 0.3050, 0.7889, 0.9688, 0.2184, 0.8626, 0.5174, 0.2072,\n",
       "         0.7216, 0.1372, 0.8630, 0.0077, 0.7831, 0.9428, 0.7768, 0.0028, 0.3397,\n",
       "         0.6889, 0.7832, 0.0338, 0.9042, 0.1507, 0.0954, 0.0186, 0.5228, 0.1703,\n",
       "         0.8765, 0.6794, 0.7727, 0.8461, 0.3734, 0.3585, 0.5264, 0.1289, 0.0443,\n",
       "         0.4084, 0.5275, 0.5002, 0.4695, 0.4656, 0.9433, 0.1772, 0.1949, 0.7622,\n",
       "         0.0347, 0.3606, 0.4741, 0.8635, 0.8085, 0.4852, 0.0319, 0.8390, 0.3790,\n",
       "         0.4657, 0.0751, 0.2338, 0.7078, 0.2001, 0.3921, 0.0315, 0.0411, 0.6679,\n",
       "         0.1056, 0.9504, 0.2028, 0.6622, 0.3399, 0.6533, 0.5816, 0.8241, 0.8458,\n",
       "         0.4681, 0.1390, 0.5809, 0.9143, 0.5676, 0.9916, 0.6861, 0.6261, 0.0601,\n",
       "         0.8386, 0.3347, 0.8764, 0.5824, 0.3936, 0.8393, 0.5468, 0.7446, 0.5885,\n",
       "         0.3914, 0.7305, 0.0609, 0.5148, 0.0372, 0.8702, 0.2104, 0.7290, 0.7220,\n",
       "         0.0099, 0.8778, 0.0596, 0.3610, 0.5669, 0.6731, 0.8547, 0.1732, 0.4232,\n",
       "         0.3846, 0.8306, 0.2163, 0.2330, 0.9564, 0.3998, 0.3509, 0.1987, 0.4703,\n",
       "         0.8612, 0.6503, 0.1487, 0.2202, 0.1653, 0.8228, 0.3390, 0.1830, 0.8521,\n",
       "         0.4125, 0.8294, 0.8419, 0.6189, 0.5401, 0.9487, 0.2751, 0.6189, 0.6305,\n",
       "         0.7509, 0.3315, 0.2635, 0.7841, 0.2422, 0.9146, 0.9680, 0.7478, 0.5692,\n",
       "         0.4168, 0.5660, 0.1272, 0.2812, 0.1665, 0.1903, 0.7794, 0.7503, 0.6225,\n",
       "         0.1892, 0.4071, 0.4573, 0.6257, 0.0341, 0.2973, 0.3814, 0.5331, 0.8404,\n",
       "         0.6970, 0.4025, 0.4971, 0.9993, 0.1183, 0.6080, 0.6910, 0.0769, 0.4670,\n",
       "         0.2511, 0.0017, 0.8546, 0.9698, 0.0569, 0.1304, 0.8891, 0.4163, 0.3591,\n",
       "         0.6733, 0.7389, 0.7150, 0.6064, 0.8490, 0.4408, 0.4599, 0.8366, 0.2011,\n",
       "         0.1968, 0.9994, 0.9763, 0.7515, 0.5029, 0.8728, 0.0915, 0.0842, 0.5474,\n",
       "         0.0409, 0.6965, 0.4495, 0.1552, 0.3989, 0.8760, 0.5225, 0.8047, 0.7261,\n",
       "         0.5069, 0.8051, 0.2224, 0.7025, 0.3261, 0.1813, 0.2786, 0.5707, 0.6145,\n",
       "         0.1598, 0.0342, 0.6405, 0.1940, 0.7362, 0.9356, 0.9690, 0.2363, 0.3645,\n",
       "         0.6255, 0.9389, 0.2381, 0.7349, 0.3313, 0.2514, 0.4456, 0.2905, 0.2432,\n",
       "         0.2811, 0.9068, 0.3198, 0.8889, 0.0646, 0.7033, 0.6267, 0.5386, 0.5916,\n",
       "         0.1089, 0.0583, 0.9560, 0.2647, 0.7239, 0.2145, 0.9427, 0.8457, 0.1870,\n",
       "         0.4630, 0.1629, 0.2888, 0.9535, 0.4319, 0.3727, 0.3381, 0.0334, 0.7925,\n",
       "         0.2207, 0.7238, 0.0103, 0.3521, 0.9215, 0.4123, 0.5295, 0.5486, 0.1124,\n",
       "         0.0714, 0.0988, 0.2062, 0.4710, 0.7892, 0.1625, 0.4606, 0.8996, 0.3319,\n",
       "         0.6843, 0.0835, 0.5362, 0.7461, 0.9001, 0.7757, 0.1648, 0.0529, 0.1778,\n",
       "         0.8253, 0.4226, 0.6145, 0.3871, 0.8604, 0.4527, 0.5673, 0.2677, 0.3294,\n",
       "         0.9450, 0.7060, 0.9786, 0.0488, 0.7231, 0.5612, 0.9101, 0.6445, 0.6250,\n",
       "         0.6959, 0.0637, 0.9150, 0.9130, 0.1907, 0.4507, 0.8603, 0.0599, 0.7121,\n",
       "         0.1498, 0.1033, 0.0983, 0.0993, 0.1646, 0.5398, 0.9941, 0.2131, 0.4836,\n",
       "         0.9786, 0.5960, 0.5057, 0.6114, 0.7682, 0.5699, 0.6322, 0.9648, 0.3344,\n",
       "         0.6822, 0.3390, 0.5444, 0.7712, 0.7750, 0.5784, 0.2696, 0.7932, 0.4554,\n",
       "         0.7518, 0.9288, 0.9712, 0.5529, 0.3311, 0.8211, 0.5557, 0.8856, 0.5688,\n",
       "         0.0263, 0.5312, 0.9950, 0.8967, 0.6474, 0.2153, 0.5960, 0.8423, 0.8383,\n",
       "         0.6542, 0.9801, 0.1281, 0.6400, 0.6519, 0.4613, 0.3728, 0.5808, 0.3130,\n",
       "         0.0160, 0.4596, 0.7970, 0.7062, 0.4415, 0.3831, 0.9558, 0.3834, 0.3965,\n",
       "         0.0339, 0.6361, 0.8425, 0.6947, 0.8186, 0.7968, 0.1939, 0.7012, 0.1509,\n",
       "         0.3021, 0.9299, 0.0985, 0.7615, 0.5733, 0.3856, 0.4481, 0.3201, 0.3559,\n",
       "         0.1916, 0.5330, 0.1293, 0.5389, 0.8239, 0.6888, 0.4329, 0.8887, 0.2982,\n",
       "         0.8381, 0.4751, 0.3106, 0.0933, 0.3572, 0.3691, 0.7089, 0.6021, 0.0141,\n",
       "         0.9458, 0.9300, 0.8129, 0.1641, 0.4856, 0.6296, 0.4243, 0.8430, 0.7623,\n",
       "         0.2984, 0.6350, 0.3429, 0.2622, 0.4195, 0.3998, 0.9766, 0.5682, 0.0320,\n",
       "         0.5002, 0.7970, 0.0128, 0.8498, 0.7677, 0.8049, 0.9377, 0.1539, 0.2455,\n",
       "         0.2705, 0.8215, 0.4084, 0.2400, 0.9925, 0.4715, 0.2584, 0.4901, 0.5694,\n",
       "         0.1107, 0.7100, 0.9552, 0.0841, 0.9565, 0.9402, 0.2932, 0.4971, 0.8525,\n",
       "         0.5920, 0.7116, 0.7338, 0.6611, 0.2771, 0.6035, 0.0435, 0.9457, 0.9926,\n",
       "         0.1240, 0.5991, 0.5028, 0.0082, 0.7825, 0.0646, 0.3852, 0.8055, 0.6925,\n",
       "         0.8009, 0.8700, 0.2440, 0.6920, 0.8731, 0.7976, 0.6552, 0.4445, 0.5106,\n",
       "         0.8312, 0.8654, 0.4228, 0.2962, 0.5531, 0.3642, 0.8595, 0.6328, 0.9340,\n",
       "         0.6179, 0.5572, 0.6260, 0.2462, 0.8616, 0.1894, 0.5865, 0.6858, 0.4299,\n",
       "         0.7239, 0.9810, 0.3331, 0.5492, 0.0565, 0.1311, 0.8738, 0.4540, 0.0585,\n",
       "         0.6107, 0.2860, 0.9122, 0.3992, 0.4323, 0.6900, 0.1416, 0.5820, 0.0111,\n",
       "         0.4336, 0.7741, 0.8932, 0.8996, 0.7416, 0.6421, 0.0653, 0.0286, 0.3829,\n",
       "         0.5039, 0.3797, 0.3852, 0.0822, 0.2106, 0.6015, 0.4404, 0.6985, 0.8912,\n",
       "         0.6786, 0.6734, 0.0505, 0.2244, 0.1035, 0.2343, 0.9813, 0.6387, 0.7766,\n",
       "         0.0695, 0.2048, 0.4856, 0.1406, 0.6829, 0.1657, 0.9953, 0.9581, 0.8557,\n",
       "         0.5662, 0.3452, 0.8910, 0.9243, 0.7049, 0.2938, 0.3943, 0.7698, 0.9088,\n",
       "         0.4730, 0.5364, 0.6560, 0.0933, 0.4427, 0.0829, 0.8482, 0.1167, 0.7615,\n",
       "         0.0386, 0.9530, 0.9089, 0.1305, 0.0136, 0.7476, 0.4559, 0.4365, 0.6141,\n",
       "         0.7862, 0.3430, 0.5888, 0.8579, 0.1775, 0.0431, 0.6181, 0.4740, 0.3032,\n",
       "         0.1267, 0.9849, 0.2439, 0.9403, 0.5599, 0.1374, 0.8038, 0.8642, 0.9392,\n",
       "         0.1800, 0.5056, 0.5657, 0.1660, 0.0500, 0.6229, 0.8916, 0.5587, 0.1663,\n",
       "         0.3234, 0.5206, 0.1036, 0.8576, 0.3277, 0.0626, 0.7265, 0.9045, 0.8626,\n",
       "         0.9882, 0.2912, 0.7429, 0.8826, 0.3192, 0.5167, 0.8583, 0.8992, 0.4153,\n",
       "         0.3706, 0.5733, 0.0854, 0.3527, 0.7577, 0.2287, 0.6063, 0.8206, 0.4363,\n",
       "         0.8762, 0.5084, 0.9605, 0.5068, 0.1628, 0.7953, 0.0987, 0.2346, 0.2032,\n",
       "         0.8346, 0.6536, 0.6384, 0.1735, 0.7998, 0.4449, 0.7959, 0.6723, 0.4629,\n",
       "         0.1429, 0.4866, 0.8018, 0.4881, 0.8985, 0.4401, 0.3868, 0.3285, 0.7245,\n",
       "         0.6700, 0.8697, 0.1680, 0.7948, 0.5728, 0.5423, 0.4826, 0.6802, 0.6756,\n",
       "         0.3729, 0.5447, 0.2345, 0.8101, 0.5442, 0.7445, 0.3569, 0.2917, 0.9346,\n",
       "         0.4103, 0.1224, 0.7221, 0.1413, 0.8368, 0.5427, 0.1792, 0.2297, 0.1431,\n",
       "         0.9374, 0.2192, 0.8623, 0.5796, 0.8867, 0.6078, 0.6964, 0.4308, 0.0289,\n",
       "         0.5181, 0.5302, 0.6153, 0.2796, 0.5786, 0.2133, 0.4388, 0.2045, 0.2316,\n",
       "         0.6001, 0.1330, 0.6039, 0.5572, 0.5572, 0.2647, 0.8460, 0.3404, 0.8277,\n",
       "         0.1726]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand((28,28))\n",
    "X = X.view(1,28*28)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.3192, -2.4110, -2.4151, -2.1682, -2.2570, -2.2495, -2.2272, -2.4674,\n",
       "         -2.3223, -2.2314]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = net(X)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PART 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0027, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0222, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0005, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr = 0.001)\n",
    "\n",
    "EPOCHS = 3\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        # datat is a batch of featuresets and labels\n",
    "        X,y = data\n",
    "        #everytime before you pass data through your neural network\n",
    "        net.zero_grad()\n",
    "        output = net(X.view(-1,28*28))\n",
    "        loss = F.nll_loss(output,y)\n",
    "        loss.backward()#backprop\n",
    "        optimizer.step()\n",
    "    print(loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.989\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testset:\n",
    "        X,y =data\n",
    "        output = net(X.view(-1,784))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "print(\"Accuracy:\", round(correct/total,3))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X[9].view(28,28), cmap=\"gray\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(6, grad_fn=<NotImplemented>)\n"
     ]
    }
   ],
   "source": [
    "print(torch.argmax(net(X[9].view(-1,784))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('base': conda)",
   "language": "python",
   "name": "python37664bitbaseconda7d6b9abbb5264fd3ab4663ee91a88227"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
